# -*- coding: utf-8 -*-
"""cleaning

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18bKgKH2gJN8Ys9wkeLXuii43CZGuzT1q
"""

def cleaning(df):
  df = pd.read_csv(url)
  null_counts = df.isnull().sum()
  count_of_duplicates = len(df) - len(df.drop_duplicates())
  df = df.drop('locationdesc', axis=1)
  drop_df=df.dropna()
  filtered_df = df[df['datavaluetype'] == 'Number']
  final_filtered=filtered_df[(filtered_df.topic=="Cardiovascular Disease")]
  final_filtered2=final_filtered.drop(['datavalueunit', 'highconfidencelimit', 'lowconfidencelimit'], axis=1)
  one_hot_encoded_data = pd.get_dummies(final_filtered2, columns = ['locationabbr'])
  final_filtered2.to_csv('final_filtered2.csv', index=False)
  data=pd.read_csv('final_filtered2.csv')
  if all(data['yearstart'] == data['yearend']):
      data = data.drop('yearend', axis=1)